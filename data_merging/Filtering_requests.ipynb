{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0624c4-c29c-4934-8918-f24b97e6fb05",
   "metadata": {},
   "source": [
    "## PII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61e818-5c5e-4676-92c6-850d321a49d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline,AutoModelForTokenClassification\n",
    "import torch\n",
    "import json\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_name = \"deepaksiloka/PII-Detection-V2.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name).to(device)\n",
    "nlp = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, device=device, aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfacd64-6ea8-4409-b2a2-0c579c8240ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./agents/GPT_results_score_PII.json\", 'r') as file:\n",
    "    pii = json.load(file)\n",
    "texts = [d['text'] for d in pii]\n",
    "\n",
    "filtered = []\n",
    "for text in texts:\n",
    "    results = nlp(text)\n",
    "    if results:  # PII exists\n",
    "        filtered.append({'text':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c5c756-cff0-4e29-a960-ebcb81446621",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./agents/GPT_results_score_PII_passed.json', 'w') as file:\n",
    "    json.dump(filtered, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84fb368-0b01-45f7-9b89-275be3f5cef9",
   "metadata": {},
   "source": [
    "## FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd82a008-f92e-4ec6-bc51-4b15d8b3ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline,AutoModelForTokenClassification\n",
    "import torch\n",
    "import json\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_name = \"jy46604790/Fake-News-Bert-Detect\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d39d6-3f1e-4c3c-8fb6-b582fc2b19ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./agents/GPT_results_score_FN.json\", 'r') as file:\n",
    "    fake = json.load(file)\n",
    "texts=[d['text'] for d in fake]\n",
    "\n",
    "encoded_inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "input_ids = encoded_inputs['input_ids'].to(device)\n",
    "attention_mask = encoded_inputs['attention_mask'].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "filtered = []\n",
    "for pred, text in zip(predictions, texts):\n",
    "    if pred[0]>pred[1]: # detected as FAKE\n",
    "        filtered.append({'text':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e080bc80-f6f1-4b6a-83a6-48289afca194",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./agents/GPT_results_score_FN_passed.json', 'w') as file:\n",
    "    json.dump(filtered, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5566e9-2e37-4e09-aa7a-6b3320e48c90",
   "metadata": {},
   "source": [
    "## CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6902c5b1-c861-485d-9198-ce336d47d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = torch.load('saved_classifier')\n",
    "model.eval()\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len=512):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_len)\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c789e09-620c-457c-aa84-b21c84863b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./agents/GPT_results_score_HP.json\", 'r') as file:\n",
    "    harrypotter = json.load(file)\n",
    "texts=[d['text'] for d in harrypotter]\n",
    "hp_dataset = TextDataset(texts, tokenizer)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(hp_dataset, batch_size=32)\n",
    "\n",
    "all_preds = []\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "\n",
    "filtered = [item for item, p in zip(texts, all_preds) if p == 1] # detected as Harry Potter excerpts\n",
    "filtered = [{\"text\": d} for d in filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1f89c-db5a-4f66-b1e0-77cc87121bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./agents/GPT_results_score_CR_passed.json', 'w') as file:\n",
    "    json.dump(filtered, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwku",
   "language": "python",
   "name": "rwku"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
